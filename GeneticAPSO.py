from random import random
import numpy as np
from geneticalgorithm import geneticalgorithm as ga
from pyswarm import pso

# MLP has been modified for this task. Implementation as a class was a little over-complicated for use with the
# chosen GA and PSO libraries.

# Create training dataset
dataset_size = 100
dataset = np.array([[random() / 2 for _ in range(2)] for _ in range(dataset_size)])
labels = np.array([[i[0] + i[1]] for i in dataset])

# Define network structure
n_inputs = 2
n_hidden_layer_neurons = [2]
n_outputs = 1

layers = [n_inputs] + n_hidden_layer_neurons + [n_outputs]

# Create activation neurons
activations = []
for i in range(len(layers)):
    nodes = np.zeros(layers[i])
    activations.append(nodes)


def ReLU(net_inputs):
    """"
    Applies Rectified Linear Unit activation function to input array.

    Parameters
        net_inputs (np.ndarray) - vector of input values

    Returns
        outputs (np.ndarray) - vector of output values

    """
    return net_inputs * (net_inputs > 0)


# Create objective function
# Takes weights as a 1D list (amenable to GA / PSO algorithm) - these will be the parameters
# optimized by the GA / PSO

def evaluate_network(weights):
    """
    Evaluates the average performance of the MLP over all items in a dataset, where performance
    is a function of the error generated by each training example.

    Paramaters
        weights (np.array) - 1D array of weights which corresponds to a flattened version
                             of the weights matrices at each layer

    """
    # Reshape 1D list of weights so they represent each weight layer
    weights_as_array = np.array(weights)
    weights_reshape = []
    for i in range(len(layers) - 1):
        layer_weights = weights_as_array[0:(layers[i] * layers[i + 1])].reshape((layers[i], layers[i + 1]))
        weights_reshape.append(layer_weights)

    # Track total error over all items in dataset
    total_error = 0

    # Forward pass all items in dataset, add error for each item
    for item, label in zip(dataset, labels):

        # Set first activations to the same values as the input
        current_activations = item
        activations[0] = item

        # Forward propagate signal
        for i, layer_weights in enumerate(weights_reshape):
            net_inputs = np.dot(current_activations, layer_weights)
            current_activations = ReLU(net_inputs)
            activations[i + 1] = current_activations

        # Get values at output layer
        output = activations[-1]

        # Calculate error and add to total error for dataset
        error = output - label
        total_error += np.sum(error ** 2)

    # Calculate average network error for one pass over dataset
    network_error = total_error / len(dataset)

    return network_error


###############################
#      Genetic algorithm      #
###############################

print("Generating and running GA-algorithm...\n")

# Give bounds for parameters for algorithm to search within
varbound = np.array([[-0.5, 1]] * 6)

# Define algorithm parameters
algorithm_param = {'max_num_iteration': 10,
                   'population_size': 5,
                   'mutation_probability': 0.1,
                   'elit_ratio': 0.1,
                   'crossover_probability': 0.5,
                   'parents_portion': 0.3,
                   'crossover_type': 'uniform',
                   'max_iteration_without_improv': None}

# Create + run model
ga_model = ga(function=evaluate_network,
              dimension=6,
              variable_type="real",
              variable_boundaries=varbound,
              algorithm_parameters=algorithm_param
              )

ga_model.run()

print("")


###############################
# Particle Swarm Optimization #
###############################

print("Generating and running PSO-algorithm...\n")

# Set bounds for search
lb = [-0.5, -0.5, -0.5, -0.5, -0.5, -0.5]
ub = [1, 1, 1, 1, 1, 1]

# Evaluate network
xopt, fopt = pso(evaluate_network, lb, ub)

print(f"\nOptimal parameters: {xopt}")
print(f"\nOptimal objective function: {fopt}")
